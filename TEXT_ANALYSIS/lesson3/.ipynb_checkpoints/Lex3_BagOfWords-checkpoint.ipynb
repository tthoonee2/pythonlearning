{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3\n",
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data and check for missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Probably my favorite cover! Super sassy and ve...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>This case protects the phone from damage.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Nice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>this was another of my favorite ones, thanks f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Decent case but not a lot of protection.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>it is so easy to put on your phone and it prot...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>Much better quality than I expected for the pr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This is one of the best screen protectors I ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This kit included a microfiber cloth and soft ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This was the easiest screen protector to put o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                                         reviewText  overall\n",
       "0      B007D6J64K  Probably my favorite cover! Super sassy and ve...        5\n",
       "1      B007D6J64K          This case protects the phone from damage.        5\n",
       "2      B007D6J64K                                               Nice        4\n",
       "3      B007D6J64K  this was another of my favorite ones, thanks f...        5\n",
       "4      B007D6J64K           Decent case but not a lot of protection.        5\n",
       "...           ...                                                ...      ...\n",
       "29995  B0096QI0QK  it is so easy to put on your phone and it prot...        5\n",
       "29996  B0096QI0QK  Much better quality than I expected for the pr...        5\n",
       "29997  B0096QI0QK  This is one of the best screen protectors I ha...        4\n",
       "29998  B0096QI0QK  This kit included a microfiber cloth and soft ...        5\n",
       "29999  B0096QI0QK  This was the easiest screen protector to put o...        5\n",
       "\n",
       "[30000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"amazon_cellphones_multiclass.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   asin        30000 non-null  object\n",
      " 1   reviewText  29988 non-null  object\n",
      " 2   overall     30000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 703.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin           0\n",
       "reviewText    12\n",
       "overall        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    17695\n",
       "4     5366\n",
       "3     3144\n",
       "1     2121\n",
       "2     1674\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable overall distribution\n",
    "\n",
    "df.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to binarize overall\n",
    "\n",
    "def binary(row):\n",
    "    if row['overall'] > 3:\n",
    "        val = 1\n",
    "    elif row['overall'] < 3:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = -1\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>bin_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Probably my favorite cover! Super sassy and ve...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>This case protects the phone from damage.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Nice</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>this was another of my favorite ones, thanks f...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B007D6J64K</td>\n",
       "      <td>Decent case but not a lot of protection.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>it is so easy to put on your phone and it prot...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>Much better quality than I expected for the pr...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This is one of the best screen protectors I ha...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This kit included a microfiber cloth and soft ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>B0096QI0QK</td>\n",
       "      <td>This was the easiest screen protector to put o...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                                         reviewText  overall  \\\n",
       "0      B007D6J64K  Probably my favorite cover! Super sassy and ve...        5   \n",
       "1      B007D6J64K          This case protects the phone from damage.        5   \n",
       "2      B007D6J64K                                               Nice        4   \n",
       "3      B007D6J64K  this was another of my favorite ones, thanks f...        5   \n",
       "4      B007D6J64K           Decent case but not a lot of protection.        5   \n",
       "...           ...                                                ...      ...   \n",
       "29995  B0096QI0QK  it is so easy to put on your phone and it prot...        5   \n",
       "29996  B0096QI0QK  Much better quality than I expected for the pr...        5   \n",
       "29997  B0096QI0QK  This is one of the best screen protectors I ha...        4   \n",
       "29998  B0096QI0QK  This kit included a microfiber cloth and soft ...        5   \n",
       "29999  B0096QI0QK  This was the easiest screen protector to put o...        5   \n",
       "\n",
       "       bin_y  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "29995      1  \n",
       "29996      1  \n",
       "29997      1  \n",
       "29998      1  \n",
       "29999      1  \n",
       "\n",
       "[30000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding the new variable to the dataset\n",
    "\n",
    "df['bin_y'] = df.apply(binary, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove all NaN and split in explicative and dependent: X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_na = df[~(df['reviewText'].isna()) & ~(df['bin_y']==-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_0 = df_not_na['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Probably my favorite cover! Super sassy and ve...\n",
       "1            This case protects the phone from damage.\n",
       "2                                                 Nice\n",
       "3    this was another of my favorite ones, thanks f...\n",
       "4             Decent case but not a lot of protection.\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_0[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This case is so cute the only problem I had with it due to the texture of the case it was hard to get in and out of my pockets'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_0[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_not_na['bin_y'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing: lowercase, remove punctuation, tokenize, lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Instantly make your loops show a smart progress meter - just wrap any iterable with tqdm(iterable), and you're done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-0bc81b41b080>:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  text = text_0.str.lower().str.replace('[^\\w\\s]',' ') # RegEx = regular expression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'case', 'is', 'so', 'cute', 'the', 'only', 'problem', 'i', 'had', 'with', 'it', 'due', 'to', 'the', 'texture', 'of', 'the', 'case', 'it', 'wa', 'hard', 'to', 'get', 'in', 'and', 'out', 'of', 'my', 'pocket']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "text = text_0.str.lower().str.replace('[^\\w\\s]',' ') # RegEx = regular expression\n",
    "\n",
    "text = text.str.split()\n",
    "\n",
    "# text = text.apply(lambda x: [lemmatizer.lemmatize(word) for sentence in x for word in sentence])\n",
    "text = text.apply(lambda x: [lemmatizer.lemmatize(sent) for sent in x])\n",
    "\n",
    "print(text[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lambda functions:   https://www.w3schools.com/python/python_lambda.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(n):\n",
    "  return lambda a : a * n\n",
    "\n",
    "mydoubler = myfunc(2)\n",
    "mytripler = myfunc(3)\n",
    "\n",
    "print(mydoubler(11))\n",
    "print(mytripler(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use lambda functions when an anonymous function is required for a short period of time, inside another function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List Comprehension: https://www.w3schools.com/python/python_lists_comprehension.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\n",
    "\n",
    "newlist = []\n",
    "for x in fruits:\n",
    "  if \"a\" in x:\n",
    "    newlist.append(x)\n",
    "\n",
    "print(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"mango\"]\n",
    "\n",
    "newlist = [x for x in fruits if \"a\" in x]\n",
    "\n",
    "print(newlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK stopwords can be found at [this link](https://gist.github.com/sebleier/554280), downloaded, custiomized and imported as a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need a new library: gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c anaconda gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using Anaconda:\n",
    "\n",
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'case', 'is', 'so', 'cute', 'the', 'only', 'problem', 'i', 'had', 'with', 'it', 'due', 'to', 'the', 'texture_of_the_case', 'it', 'wa_hard', 'to', 'get', 'in', 'and', 'out', 'of', 'my', 'pocket']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['good', 'many', 'love', 'excellent', 'would'])\n",
    "\n",
    "bigram = Phrases(text, min_count=5, threshold=0.2, connector_words=stop)\n",
    "print(bigram[text[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold parameter:\n",
    "<img src='img/phrases_threshold.PNG' width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'case', 'is', 'so', 'cute', 'the', 'only', 'problem', 'i', 'had', 'with', 'it', 'due', 'to', 'the', 'texture_of_the_case', 'it', 'wa_hard', 'to', 'get', 'in', 'and', 'out', 'of', 'my', 'pocket']\n"
     ]
    }
   ],
   "source": [
    "bigrams = [bigram[item] for item in text]\n",
    "ngrams = [bigram[item] for item in bigrams]\n",
    "print(ngrams[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['probably', 'my', 'favorite', 'cover', 'super', 'sassy', 'and', 'very', 'protective', 'i', 'am', 'very', 'abusive', 'of', 'my', 'phone', 'and', 'this', 'case', 'held_up_very_well', 'after', 'a', 'year', 'the', 'color', 'started', 'to', 'wear', 'a', 'bit', 'but', 'it', 'continued', 'to', 'protect_my_phone', 'very', 'well', 'i', 'would', 'buy', 'it', 'again']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'case cute problem due texture_of_the_case wa_hard get pocket'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['good', 'bad', 'dont', 'many', 'love', 'excellent', 'would', 'perfect', 'even', 'great'])\n",
    "\n",
    "print(ngrams[0])\n",
    "train_sentences = []\n",
    "for row in ngrams:\n",
    "    train_sentences.append(' '.join([item for item in row if item not in stop]))\n",
    "# train_sentences = [' '.join(item) for item in ngrams]\n",
    "train_sentences[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-68415c32931d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not_na['reviewText'] = train_sentences\n"
     ]
    }
   ],
   "source": [
    "df_not_na['reviewText'] = train_sentences\n",
    "df_not_na.to_csv('amazon_cellphones_binary.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words:\n",
    "<img src='img/bow.PNG' width='600'>\n",
    "\n",
    "Term frequency - inverse document frequency:\n",
    "<img src='img/tfidf.jpeg' width='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), max_features=1000)\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=1000)\n",
    "\n",
    "X = vectorizer.fit_transform(train_sentences)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "X = X.toarray()\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  [86.90932311621967, 86.41443167305236, 86.66773111927192]\n",
      "recall:  [0.8769637836943939, 0.872245971719829, 0.8746495134421903]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "model = tree.DecisionTreeClassifier(max_leaf_nodes=10, max_depth=5)\n",
    "# model = LogisticRegression(class_weight=None)\n",
    "# model = RandomForestClassifier()\n",
    "\n",
    "cvscores = []\n",
    "cvrecall = []\n",
    "\n",
    "for train, test in tqdm(kfold.split(x_train, y_train)):\n",
    "    model.fit(x_train[train],y_train[train])\n",
    "    predicted = model.predict(x_train[test])\n",
    "    scores = accuracy_score(predicted, y_train[test])\n",
    "    recall = recall_score(predicted, y_train[test])\n",
    "    cvrecall.append(recall)\n",
    "    cvscores.append(scores * 100)\n",
    "\n",
    "print(\"accuracy: \",cvscores)\n",
    "print(\"recall: \",cvrecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.12      0.20      1138\n",
      "           1       0.87      0.99      0.93      6916\n",
      "\n",
      "    accuracy                           0.87      8054\n",
      "   macro avg       0.75      0.55      0.56      8054\n",
      "weighted avg       0.84      0.87      0.82      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validated grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Wall time: 8min 39s\n",
      "Best: 0.856129 using {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.839784 (0.005370) with: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.844289 (0.002538) with: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.837271 (0.002848) with: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.851750 (0.000699) with: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.835758 (0.000493) with: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.849854 (0.001796) with: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.805314 (0.024144) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.825892 (0.008594) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.792501 (0.005277) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.825981 (0.006194) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.810517 (0.008519) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.824695 (0.004084) with: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.809384 (0.009318) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.838753 (0.003259) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.804729 (0.008766) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.835823 (0.003582) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.811564 (0.013293) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.832214 (0.005765) with: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.845627 (0.002975) with: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.849371 (0.006014) with: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.849235 (0.002599) with: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.856129 (0.002818) with: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.842279 (0.002441) with: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.856019 (0.003113) with: {'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.802003 (0.007354) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.829760 (0.008756) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.810323 (0.003904) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.829281 (0.013417) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.798120 (0.011425) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.828597 (0.004230) with: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 20, 'n_estimators': 100}\n",
      "0.817993 (0.005572) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "0.835676 (0.005106) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "0.819389 (0.010369) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 10}\n",
      "0.839268 (0.003538) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "0.817852 (0.002495) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 10}\n",
      "0.834378 (0.004844) with: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 20, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "#cross_validated_grid_search for Random Forest\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "param_grid = {'n_estimators': [10, 100],\n",
    "               'criterion': ['gini', 'entropy'],\n",
    "               'max_depth': [None, 5, 10],\n",
    "               'min_samples_split': [2, 10, 20]}\n",
    "\n",
    "#cross_validated_grid_search for SVC\n",
    "# model = svm.SVC()\n",
    "# param_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv=3, verbose=2, n_jobs=-1, scoring='f1_weighted')\n",
    "# Fit the random search model\n",
    "%time grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "#print grid search results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.40      0.46      1138\n",
      "           1       0.91      0.94      0.92      6916\n",
      "\n",
      "    accuracy                           0.87      8054\n",
      "   macro avg       0.73      0.67      0.69      8054\n",
      "weighted avg       0.85      0.87      0.86      8054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "predicted = best_model.predict(x_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
