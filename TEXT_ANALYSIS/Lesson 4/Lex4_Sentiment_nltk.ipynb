{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe443eb",
   "metadata": {},
   "source": [
    "# Lesson 4\n",
    "## Sentiment using nltk¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5403a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff92be",
   "metadata": {},
   "source": [
    "**Element to download:**\n",
    "\n",
    "names: A list of common English names compiled by Mark Kantrowitz\n",
    "\n",
    "stopwords: A list of really common words, like articles, pronouns, prepositions, and conjunctions\n",
    "\n",
    "state_union: A sample of transcribed State of the Union addresses by different US presidents, compiled by Kathleen Ahrens\n",
    "\n",
    "twitter_samples: A list of social media phrases posted to Twitter\n",
    "\n",
    "movie_reviews: Two thousand movie reviews categorized by Bo Pang and Lillian Lee\n",
    "\n",
    "averaged_perceptron_tagger: A data model that NLTK uses to categorize words into their part of speech\n",
    "\n",
    "vader_lexicon: A scored list of words and jargon that NLTK references when performing sentiment analysis, created by C.J. Hutto and Eric Gilbert\n",
    "\n",
    "punkt: A data model created by Jan Strunk that NLTK uses to split full texts into word lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84822214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Utente\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\n",
    "     \"names\",\n",
    "     \"stopwords\",\n",
    "     \"state_union\",\n",
    "     \"twitter_samples\",\n",
    "     \"movie_reviews\",\n",
    "     \"averaged_perceptron_tagger\",\n",
    "     \"vader_lexicon\",\n",
    "     \"punkt\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2ffc024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalternative --> use   nltk.word_tokenize(   )\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the State of the Union corpus\n",
    "\n",
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]  # deletes punctuation\n",
    "\n",
    "'''\n",
    "alternative --> use   nltk.word_tokenize(   )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56a0ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'S',\n",
       " 'TRUMAN',\n",
       " 'S',\n",
       " 'ADDRESS',\n",
       " 'BEFORE',\n",
       " 'A',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'It',\n",
       " 'is',\n",
       " 'with',\n",
       " 'a',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'that',\n",
       " 'I',\n",
       " 'stand',\n",
       " 'before',\n",
       " 'you',\n",
       " 'my',\n",
       " 'friends',\n",
       " 'and',\n",
       " 'colleagues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Congress',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'States',\n",
       " 'Only',\n",
       " 'yesterday',\n",
       " 'we',\n",
       " 'laid',\n",
       " 'to',\n",
       " 'rest']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767197db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "words = [w for w in words if w.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212ce488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRESIDENT',\n",
       " 'HARRY',\n",
       " 'TRUMAN',\n",
       " 'ADDRESS',\n",
       " 'JOINT',\n",
       " 'SESSION',\n",
       " 'CONGRESS',\n",
       " 'April',\n",
       " 'Mr',\n",
       " 'Speaker',\n",
       " 'Mr',\n",
       " 'President',\n",
       " 'Members',\n",
       " 'Congress',\n",
       " 'heavy',\n",
       " 'heart',\n",
       " 'stand',\n",
       " 'friends',\n",
       " 'colleagues',\n",
       " 'Congress',\n",
       " 'United',\n",
       " 'States',\n",
       " 'yesterday',\n",
       " 'laid',\n",
       " 'rest',\n",
       " 'mortal',\n",
       " 'remains',\n",
       " 'beloved',\n",
       " 'President',\n",
       " 'Franklin',\n",
       " 'Delano',\n",
       " 'Roosevelt',\n",
       " 'time',\n",
       " 'like',\n",
       " 'words',\n",
       " 'inadequate',\n",
       " 'eloquent',\n",
       " 'tribute',\n",
       " 'would',\n",
       " 'reverent',\n",
       " 'silence',\n",
       " 'Yet',\n",
       " 'decisive',\n",
       " 'hour',\n",
       " 'world',\n",
       " 'events',\n",
       " 'moving',\n",
       " 'rapidly',\n",
       " 'silence',\n",
       " 'might']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86c7fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word frequency distribution\n",
    "\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f95fdb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('must', 1568),\n",
       " ('people', 1291),\n",
       " ('world', 1128),\n",
       " ('year', 1097),\n",
       " ('America', 1076),\n",
       " ('us', 1049),\n",
       " ('new', 1049),\n",
       " ('Congress', 1014),\n",
       " ('years', 827),\n",
       " ('American', 784)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words\n",
    "\n",
    "fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cc611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.tabulate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5854f215",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd[\"America\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac79abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd[\"america\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d76486",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd[\"AMERICA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4441d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase word frequencies\n",
    "\n",
    "lower_words = [w.lower() for w in words]\n",
    "lower_fd = nltk.FreqDist(lower_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_fd[\"america\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a1a1a7",
   "metadata": {},
   "source": [
    "In the context of NLP, a **concordance** is a collection of word locations along with their context. You can use concordances to find:\n",
    "\n",
    "- How many times a word appears\n",
    "- Where each occurrence appears\n",
    "- What words surround each occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2baac1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = nltk.Text(nltk.corpus.state_union.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0036bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 1079 matches:\n",
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n",
      " to make complete victory certain , America will never become a party to any pl\n",
      "nly in law and in justice . Here in America , we have labored long and hard to \n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"america\", lines=5)   # .concordance() already ignores case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2024a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " would want us to do . That is what America will do . So much blood has already\n",
      "ay , the entire world is looking to America for enlightened leadership to peace\n",
      "beyond any shadow of a doubt , that America will continue the fight for freedom\n"
     ]
    }
   ],
   "source": [
    "concordance_list = text1.concordance_list(\"america\", lines=3)\n",
    "\n",
    "for entry in concordance_list:\n",
    "    print(entry.line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccfe23",
   "metadata": {},
   "source": [
    "**Collocations** can be made up of two or more words. NLTK provides classes to handle several types of collocations:\n",
    "\n",
    "- Bigrams: Frequent two-word combinations\n",
    "- Trigrams: Frequent three-word combinations\n",
    "- Quadgrams: Frequent four-word combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f92f10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "finder = nltk.collocations.TrigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc91a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'United', 'States'), 294),\n",
       " (('the', 'American', 'people'), 185),\n",
       " (('of', 'the', 'world'), 154),\n",
       " (('of', 'the', 'United'), 145),\n",
       " (('to', 'the', 'Congress'), 139)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder.ngram_fd.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bf2cab",
   "metadata": {},
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f73b49",
   "metadata": {},
   "source": [
    "NLTK already has a built-in, pretrained sentiment analyzer called VADER (Valence Aware Dictionary and sEntiment Reasoner)\n",
    "\n",
    "VADER needs raw strings for its rating!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf244f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36407ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61a57640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataset\n",
    "\n",
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]  # list of raw tweets as strings, we disable\n",
    "#the urls in order not to open unwanted webpages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d238455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hopeless for tmr :(',\n",
       " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\",\n",
       " '@Hegelbon That heart sliding into the waste basket. :(',\n",
       " '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
       " 'Dang starting next week I have \"work\" :(',\n",
       " \"oh god, my babies' faces :( https//t.co/9fcwGvaki0\",\n",
       " '@RileyMcDonough make me smile :((',\n",
       " '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http//t.co/XvmTUikWln',\n",
       " 'why?:(\"@tahuodyy: sialan:( https//t.co/Hv1i0xcrL2\"',\n",
       " 'Athabasca glacier was there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http//t.co/dZZdqmf7Cz']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "643c6dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> False I haven't gotten any sleep and I have to be up in 3 1/2 hours :)))))))))))))))\n",
      "> True RT @Tommy_Colc: Financial Times come out in support of Tories claiming Miliband is \"preoccupied w/ inequality\". The man who wrote it http:/…\n",
      "> False RT @HumzaYousaf: That sound you hear is the final nail hammered into New Labour coffin as Ed Miliband says he'd rather let Tories in than w…\n",
      "> False RT @natalieben: #bbcqt Miliband: \"I'm the 1st Labour leader going into an election saying spending in key areas is going to fall\" #austeria…\n",
      "> True @smartcookiesam @Confarreo I played dominoes in a pub once. It all got quite heated! Enjoyed it though :D\n",
      "> True RT @amiablecynic: I'm a #GreenParty member but I'll vote #Labour because I believe Ed has the best chance of ending #Tory rule #dontvotegre…\n",
      "> False RT @LucioFulciFan: @ChristinaSNP Maybe now even the thickest Labourites in Scotland can see Labour would rather side with the Tories than s…\n",
      "> False RT @Plaid_Cymru: Miliband confirms he would rather let Tories in than work with SNP @RhunapIorwerth https//t.co/8r3eC0WF1E #Plaid15 #GE2015\n",
      "> True hugs baek tight : (\n",
      "> False http//t.co/QgDJRG8ddN #BBC bias against #UKIP shows itself once again as it squeezes out Nigel_Farage from the … https//t.co/QfsEtqQj23\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def is_positive(tweet: str) -> bool:\n",
    "    \"\"\"True if tweet has positive compound sentiment, False otherwise.\"\"\"\n",
    "    return sia.polarity_scores(tweet)[\"compound\"] > 0.1\n",
    "\n",
    "shuffle(tweets)\n",
    "for tweet in tweets[:10]:\n",
    "    print(\">\", is_positive(tweet), tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8a3ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
